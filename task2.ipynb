{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "942a2c54",
   "metadata": {},
   "source": [
    "# Second lab assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69007eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, RidgeCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5fca7e",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa0ef58",
   "metadata": {},
   "source": [
    "After reading the data from the csv file, we check if there any missing values, and then prepare our features X without the class and output columns, and prepare the vectors representing these columns for regression and classification. The whole dataset is split into a training and test set in a stratified manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27939281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Before dropping missing data: ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Columns: 402 entries, Class to Input400\n",
      "dtypes: float64(401), int64(1)\n",
      "memory usage: 6.1 MB\n",
      "None\n",
      "--- After dropping missing data: ---\n",
      "(2000, 402)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('task2_data.csv', sep=';')\n",
    "# Print info about the dataset before and after dropping missing data\n",
    "print('--- Before dropping missing data: ---')\n",
    "print(df.info())\n",
    "df = df.dropna()\n",
    "print('--- After dropping missing data: ---')\n",
    "print(df.shape)\n",
    "\n",
    "# Prepare the training and testing data\n",
    "X = df.drop(columns=['Class', 'Output']).to_numpy()\n",
    "y_output = df['Output'].to_numpy()\n",
    "y_class = df['Class'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_output_train, y_output_test, y_class_train, y_class_test = train_test_split(\n",
    "    X, y_output, y_class, test_size=0.2, random_state=1, stratify=y_class\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7fe072",
   "metadata": {},
   "source": [
    "## Task 1. Building baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62dea21",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "For the baseline regression, we use a simple linear regression model with no scaling of the features. We assess model performance using $R^2$ scores computed across 5-fold cross-validation train-test splits and then the $R^2$ score computed for the model trained on the whole training set and evaluated on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825a03ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline regression R^2 on training set during cross-validation: 0.6658 ± 0.0035\n",
      "Baseline regression R^2 during cross-validation: 0.3043 ± 0.0344\n",
      "Baseline regression R^2 on training set: 0.6365\n",
      "Baseline regression R^2 on test set: 0.2939\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "r2_scores = []\n",
    "r2_train_scores = []\n",
    "for train_index, test_index in cv.split(X_train):\n",
    "    X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
    "    y_output_train_cv, y_output_test_cv = y_output_train[train_index], y_output_train[test_index]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_cv, y_output_train_cv)\n",
    "    y_pred = model.predict(X_test_cv)\n",
    "    r2_scores.append(r2_score(y_output_test_cv, y_pred))\n",
    "    r2_train_scores.append(r2_score(y_output_train_cv, model.predict(X_train_cv)))\n",
    "\n",
    "print(f'Baseline regression R^2 on training set during cross-validation: {np.mean(r2_train_scores):.4f} ± {np.std(r2_train_scores):.4f}')\n",
    "print(f'Baseline regression R^2 during cross-validation: {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}')\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_output_train)\n",
    "print(f'Baseline regression R^2 on training set: {r2_score(y_output_train, model.predict(X_train)):.4f}')\n",
    "print(f'Baseline regression R^2 on test set: {r2_score(y_output_test, model.predict(X_test)):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9062574d",
   "metadata": {},
   "source": [
    "The baseline model has a high $R^2$ on the training set, but it is a lot lower on the test sets, which shows that the model overfits and does not generalize well beyond the training data. We see that the baseline regression model has a relatively low $R^2$ score of around 0.3 for both the cross-validation score and the score on the test set, so we should explore more complex models or feature engineering for a better explanation of the output variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae7ba44",
   "metadata": {},
   "source": [
    "### Classification\n",
    "For the baseline classification we use a logistic regression with no feature scaling. We assess the performance of the classifier using the same strategy as for the baseline regression model (with stratified cross validation) with accuracy as our performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ba406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline classification accuracy on training set during cross-validation: 0.7631 ± 0.0097\n",
      "Baseline classification accuracy during cross-validation: 0.5194 ± 0.0236\n",
      "Baseline classification accuracy on training set: 0.7238\n",
      "Baseline classification accuracy on test set: 0.5050\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "accuracy_scores = []\n",
    "train_accuracy_scores = []\n",
    "for train_index, test_index in cv.split(X_train, y_class_train):\n",
    "    X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
    "    y_class_train_cv, y_class_test_cv = y_class_train[train_index], y_class_train[test_index]\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_cv, y_class_train_cv)\n",
    "    accuracy_scores.append(accuracy_score(y_class_test_cv, model.predict(X_test_cv)))\n",
    "    train_accuracy_scores.append(accuracy_score(y_class_train_cv, model.predict(X_train_cv)))\n",
    "\n",
    "accuracy = np.mean(accuracy_scores)\n",
    "accuracy_std = np.std(accuracy_scores)\n",
    "print(f'Baseline classification accuracy on training set during cross-validation: {np.mean(train_accuracy_scores):.4f} ± {np.std(train_accuracy_scores):.4f}')\n",
    "print(f'Baseline classification accuracy during cross-validation: {accuracy:.4f} ± {accuracy_std:.4f}')\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_class_train)\n",
    "print(f'Baseline classification accuracy on training set: {accuracy_score(y_class_train, model.predict(X_train)):.4f}')\n",
    "print(f'Baseline classification accuracy on test set: {accuracy_score(y_class_test, model.predict(X_test)):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91261181",
   "metadata": {},
   "source": [
    "Similarly to the baseline regression, the model overfits and does not generalize beyond the training data -- the accuracy is a lot higher on the training set and on the test set it is comparable to random guessing, the model performs very poorly, with an accuracy score of around 0.5 for both the cross-validation score and score on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de7c3ef",
   "metadata": {},
   "source": [
    "## Task 2. Advanced classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941990e",
   "metadata": {},
   "source": [
    "\n",
    "For advanced classification, we use a pipeline combining feature selection and a non-linear classifier.\n",
    "\n",
    "For feature selection Random Forests are used within a 15-fold inner cross-validation to compute feature importances. The top 15 most important features are selected based on the average importances from each fold, which makes feature selection more stable. A Support Vector Classifier with an RBF kernel was trained on the selected features. This model is chosen for its ability to capture non-linear relationships in the data, which is first scaled using a StandardScaler to ensure all features contribute equally to the model. \n",
    "\n",
    "Many hyperparameters (e.g., number of selected features, SVC kernel parameters, Random Forest depth) can be tuned for this pipeline. However, a full grid search would be computationally quite expensive, so the main parameters were tuned manually based on validation performance before seeing the model perform on the test set, but to have some kind of parameter optimization a grid search is performed for the best C parameter of the final Support Vector Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "981c404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification train accuracy during cross-validation: 0.8464 ± 0.0063\n",
      "Classification accuracy during cross-validation: 0.7919 ± 0.0149\n",
      "Final Train Accuracy: 0.8462\n",
      "Final Test Accuracy: 0.7950\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       197\n",
      "           1       0.80      0.80      0.80       203\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.79      0.79      0.79       400\n",
      "weighted avg       0.79      0.80      0.79       400\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[155  42]\n",
      " [ 40 163]]\n",
      "selected features: [239  40 292   1 395 329 245 255 237  39 136  37 149 307 205]\n"
     ]
    }
   ],
   "source": [
    "# Number of features to select for classification\n",
    "k = 15\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "accuracy_scores = []\n",
    "train_accuracy_scores = []\n",
    "\n",
    "def get_classifier(X_t, y_t):\n",
    "    # We assumme that the data is already scaled, so we do not scale it again\n",
    "\n",
    "    # Inner cross-validation for feature selection using Random Forest to compute feature importances\n",
    "    # There is a lot of folds to try to pick the stable important features\n",
    "    inner_cv = StratifiedKFold(n_splits=15, shuffle=True, random_state=1)\n",
    "    feature_importances_sum = np.zeros(X_t.shape[1])\n",
    "\n",
    "    for train_inner_index, test_inner_index in inner_cv.split(X_t, y_t):\n",
    "        X_train_inner, X_test_inner = X_t[train_inner_index], X_t[test_inner_index]\n",
    "        y_train_inner, y_test_inner = y_t[train_inner_index], y_t[test_inner_index]\n",
    "\n",
    "        # The model has a shallower depth to avoid overfitting\n",
    "        model = RandomForestClassifier(n_estimators=20, random_state=1, max_depth=7)\n",
    "        model.fit(X_train_inner, y_train_inner)\n",
    "        \n",
    "        feature_importances_sum += model.feature_importances_\n",
    "\n",
    "    # Average feature importances over all folds and get the indices of the top k features\n",
    "    feature_importances_avg = feature_importances_sum / inner_cv.get_n_splits()\n",
    "    selected_features = np.argsort(feature_importances_avg)[::-1][:k]\n",
    "    X_t_reduced = X_t[:, selected_features]\n",
    "\n",
    "    # The final model is trained using SVC with RBF kernel\n",
    "    # We use GridSearchCV to find the best hyperparameter C\n",
    "    param_grid = {'C': [0.1, 1.0, 2.0, 4.0, 8.0]}\n",
    "    svc = SVC(kernel='rbf', random_state=1)\n",
    "    grid = GridSearchCV(svc, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_t_reduced, y_t)\n",
    "    model = grid.best_estimator_\n",
    "    return model, selected_features\n",
    "\n",
    "\n",
    "for train_index, test_index in cv.split(X_train, y_class_train):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
    "    y_class_train_cv, y_class_test_cv = y_class_train[train_index], y_class_train[test_index]\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_cv_scaled = scaler.fit_transform(X_train_cv)\n",
    "    X_test_cv_scaled = scaler.transform(X_test_cv)\n",
    "\n",
    "    # Get the classifier and selected features\n",
    "    model, selected_features = get_classifier(X_train_cv_scaled, y_class_train_cv)\n",
    "\n",
    "    # Evaluate the model on the test set and training set to see if it overfits a lot\n",
    "    accuracy = accuracy_score(y_class_test_cv, model.predict(X_test_cv_scaled[:, selected_features]))\n",
    "    train_accuracy = accuracy_score(y_class_train_cv, model.predict(X_train_cv_scaled[:, selected_features]))\n",
    "    accuracy_scores.append(accuracy)\n",
    "    train_accuracy_scores.append(train_accuracy)\n",
    "\n",
    "print(f'Classification train accuracy during cross-validation: {np.mean(train_accuracy_scores):.4f} ± {np.std(train_accuracy_scores):.4f}')\n",
    "print(f'Classification accuracy during cross-validation: {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}')\n",
    "\n",
    "# Fit the final model on the entire training set and evaluate on the test set to see how it generalizes with the chosen hyperparameters\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "final_classifier, selected_features = get_classifier(X_train_scaled, y_class_train)\n",
    "y_pred = final_classifier.predict(X_test_scaled[:, selected_features])\n",
    "\n",
    "test_accuracy = accuracy_score(y_class_test, y_pred)\n",
    "train_accuracy = accuracy_score(y_class_train, final_classifier.predict(X_train_scaled[:, selected_features]))\n",
    "print(f'Final Train Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Final Test Accuracy: {test_accuracy:.4f}')\n",
    "print('--- Classification Report ---')\n",
    "print(classification_report(y_class_test, y_pred))\n",
    "print('--- Confusion Matrix ---')\n",
    "print(confusion_matrix(y_class_test, y_pred))\n",
    "\n",
    "print('selected features:', selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3cd26a",
   "metadata": {},
   "source": [
    "The cross-validation accuracy is significantly improved compared to the baseline, with mean train accuracy around 0.84 and test accuracy of around 0.79, which are of course much higher than random guessing. However, there is a slight overfitting, as the training accuracy is a bit higher than the test accuracy. This suggests the model captures complex patterns but could benefit from further regularization or more robust hyperparameter optimization. Overall, the process selects informative features and uses a classifier to achieve stronger generalization, and almost reaches the performance of more than 0.8 as was stated in the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae3e5eb",
   "metadata": {},
   "source": [
    "## Task 3. Advanced regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce0e2af",
   "metadata": {},
   "source": [
    "The advanced regression pipeline combines feature selection with regularized regression to improve predictive performance. Feature selection is performed using permutation importance with Ridge regression in a nested cross-validation setup, ensuring that only the most informative features (top 15) are retained for modeling. The final model is a RidgeCV regressor, which automatically optimizes its parameter (the regularization strength) to prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae0b006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R^2 on training set during cross-validation: 0.5316 ± 0.0048\n",
      "Average R^2 during cross-validation: 0.5181 ± 0.0179\n",
      "Final Train R^2: 0.5303\n",
      "Final Test R^2: 0.4768\n",
      "selected features: [222 166  82 341 192 291 172 183 135 386  58  17 240 388 206]\n"
     ]
    }
   ],
   "source": [
    "k_r = 15 # Number of features to select for regression\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "r2_scores = []\n",
    "r2_train_scores = []\n",
    "\n",
    "def get_regressor(X_t, y_t):\n",
    "    # Inner cross-validation for feature selection using permutation importance and Ridge regression\n",
    "    inner_cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    feature_importances_sum = np.zeros(X_t.shape[1])\n",
    "\n",
    "    for train_inner_index, test_inner_index in inner_cv.split(X_t):\n",
    "        X_train_inner, X_test_inner = X_t[train_inner_index], X_t[test_inner_index]\n",
    "        y_train_inner, y_test_inner = y_t[train_inner_index], y_t[test_inner_index]\n",
    "\n",
    "        # Fit model since data is already scaled\n",
    "        model = RidgeCV(alphas=[0.1, 1.0, 10.0, 20.0])\n",
    "        model.fit(X_train_inner, y_train_inner)\n",
    "\n",
    "        # Permutation importance on the inner test set\n",
    "        result = permutation_importance(model, X_test_inner, y_test_inner,\n",
    "                                        scoring='r2', n_repeats=4, random_state=1)\n",
    "        \n",
    "        # Accumulate feature importances\n",
    "        feature_importances = result.importances_mean\n",
    "        # Sum the feature importances across folds\n",
    "        feature_importances_sum += feature_importances\n",
    "\n",
    "    # Average feature importances over all folds and get the indices of the top k features\n",
    "    feature_importances_avg = feature_importances_sum / inner_cv.get_n_splits()\n",
    "    selected_features = np.argsort(feature_importances_avg)[::-1][:k_r]\n",
    "    X_t_reduced = X_t[:, selected_features]\n",
    "\n",
    "    # The final model is trained using Ridge regression with cross-validation\n",
    "    model = RidgeCV(alphas=[0.1, 1.0, 10.0, 20.0])\n",
    "    model.fit(X_t_reduced, y_t)\n",
    "    return model, selected_features\n",
    "\n",
    "for outer_train_idx, outer_test_idx in cv.split(X_train):\n",
    "    # Split into outer train/test\n",
    "    X_outer_train, X_outer_test = X_train[outer_train_idx], X_train[outer_test_idx]\n",
    "    y_outer_train, y_outer_test = y_output_train[outer_train_idx], y_output_train[outer_test_idx]\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_outer_train_scaled = scaler.fit_transform(X_outer_train)\n",
    "    X_outer_test_scaled = scaler.transform(X_outer_test)\n",
    "\n",
    "    # Get the regressor and selected features\n",
    "    final_regressor, selected_features = get_regressor(X_outer_train_scaled, y_outer_train)\n",
    "\n",
    "    # Evaluate on outer test set\n",
    "    r2 = r2_score(y_outer_test, final_regressor.predict(X_outer_test_scaled[:, selected_features]))\n",
    "    r2_scores.append(r2)\n",
    "    r2_train = r2_score(y_outer_train, final_regressor.predict(X_outer_train_scaled[:, selected_features]))\n",
    "    r2_train_scores.append(r2_train)\n",
    "\n",
    "# Print the average R^2\n",
    "print(f'Average R^2 on training set during cross-validation: {np.mean(r2_train_scores):.4f} ± {np.std(r2_train_scores):.4f}')\n",
    "print(f\"Average R^2 during cross-validation: {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n",
    "\n",
    "# Fit the final regressor on the entire training set and evaluate on the test set\n",
    "\n",
    "# Scale the entire training and test set\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "final_regressor, selected_features = get_regressor(X_train_scaled, y_output_train)\n",
    "test_r2 = r2_score(y_output_test, final_regressor.predict(X_test_scaled[:, selected_features]))\n",
    "train_r2 = r2_score(y_output_train, final_regressor.predict(X_train_scaled[:, selected_features]))\n",
    "\n",
    "print(f'Final Train R^2: {train_r2:.4f}')\n",
    "print(f'Final Test R^2: {test_r2:.4f}')\n",
    "\n",
    "print('selected features:', selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a96058",
   "metadata": {},
   "source": [
    "Results show a substantial improvement over the baseline: the average $R^2$ score during cross-validation is approximately 0.52, and the final test $R^2$ is about 0.48. It is a bit lower than the one seen during cross-validation, but is within three standard deviations, so this is probably just a test set which was harder to predict for the model. We can also see that the difference between the $R^2$ during training and testing is a lot smaller (particularly for the cross-validation means), which indicates that the model generalizes better and does not overfit as much as the baseline. The model explains nearly half of the variance in the output variable, though there is still room for improvement, possibly through more advanced models or further feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42328f62",
   "metadata": {},
   "source": [
    "## Validation on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e754d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('validation_data.csv', sep=';')\n",
    "X_val = new_data.drop(columns=['Class', 'Output']).to_numpy()\n",
    "y_output_val = new_data['Output'].to_numpy()\n",
    "y_class_val = new_data['Class'].to_numpy()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the models on the training data and compute the scores on the validation data\n",
    "\n",
    "# Baseline regression\n",
    "baseline_regression = LinearRegression()\n",
    "baseline_regression.fit(X, y_output)\n",
    "baseline_r2 = r2_score(y_output_val, baseline_regression.predict(X_val))\n",
    "print(f'Baseline regression R^2 on validation set: {baseline_r2:.4f}')\n",
    "\n",
    "# Advanced regression\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "advanced_regression, selected_features = get_regressor(X_scaled, y_output)\n",
    "advanced_r2 = r2_score(y_output_val, advanced_regression.predict(scaler.transform(X_val)[:, selected_features]))\n",
    "print(f'Advanced regression R^2 on validation set: {advanced_r2:.4f}')\n",
    "\n",
    "# Baseline classification\n",
    "baseline_classification = LogisticRegression()\n",
    "baseline_classification.fit(X, y_class)\n",
    "baseline_accuracy = accuracy_score(y_class_val, baseline_classification.predict(X_val))\n",
    "print(f'Baseline classification accuracy on validation set: {baseline_accuracy:.4f}')\n",
    "\n",
    "# Advanced classification\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "advanced_classification, selected_features = get_classifier(X_scaled, y_class)\n",
    "advanced_accuracy = accuracy_score(y_class_val, advanced_classification.predict(scaler.transform(X_val)[:, selected_features]))\n",
    "print(f'Advanced classification accuracy on validation set: {advanced_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
